- Fashion Mnist 데이터 인풋 관련해서는 
- https://www.tensorflow.org/tutorials/keras/basic_classification
- 를 참조했습니다


```python
%load_ext watermark
%watermark -a 'Sebastian Raschka' -v -p tensorflow
```

    UsageError: unrecognized arguments: Raschka'



```python
from __future__ import absolute_import, division, print_function, unicode_literals, unicode_literals

# tensorflow와 tf.keras를 임포트합니다
import tensorflow as tf
from tensorflow import keras

# 헬퍼(helper) 라이브러리를 임포트합니다
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)
```


```python
fashion_mnist = keras.datasets.fashion_mnist

(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()
```

- data 전처리. 0~1 사이의 값으로 변환


```python
train_images = train_images / 255.0

test_images = test_images / 255.0
```

- 편의상 input data의 형태를 (x,784)로 변경하겠습니다.


```python
train_images_flatten = []
for i in range(len(train_images)):
    train_images_flatten.append(train_images[i].reshape(-1))
train_images_flatten=np.array(train_images_flatten)    
```


    ---------------------------------------------------------------------------

    NameError                                 Traceback (most recent call last)

    <ipython-input-2-07e0a9225a93> in <module>
          1 train_images_flatten = []
    ----> 2 for i in range(len(train_images)):
          3     train_images_flatten.append(train_images[i].reshape(-1))
          4 train_images_flatten=np.array(train_images_flatten)


    NameError: name 'train_images' is not defined



```python
test_images_flatten = []
for i in range(len(test_images)):
    test_images_flatten.append(test_images[i].reshape(-1))
test_images_flatten=np.array(test_images_flatten) 
```

- Hyper parmeter와 히든 계층의 노드의 수 셋팅입니다


```python
# Hyperparameters
learning_rate = 0.1
training_epochs = 10
batch_size = 60

# Architecture
n_hidden_1 = 128
n_hidden_2 = 256
n_input = 784
n_classes = 10
```


```python
##########################
### GRAPH DEFINITION
##########################

g = tf.Graph()
with g.as_default():

    # Input data
    tf_x = tf.placeholder(tf.float32, [None, n_input], name='features')
    tf_y = tf.placeholder(tf.float32, [None, n_classes], name='targets')

    # Multilayer perceptron
    layer_1 = tf.layers.dense(tf_x, n_hidden_1, activation=tf.nn.relu, 
                              kernel_initializer=tf.truncated_normal_initializer(stddev=0.1))
    layer_2 = tf.layers.dense(layer_1, n_hidden_2, activation=tf.nn.relu,
                              kernel_initializer=tf.truncated_normal_initializer(stddev=0.1))
    out_layer = tf.layers.dense(layer_2, n_classes, activation=None)

    # Loss and optimizer
    loss = tf.nn.softmax_cross_entropy_with_logits(logits=out_layer, labels=tf_y)
    cost = tf.reduce_mean(loss, name='cost')
    optimizer = tf.train.GradientDescentOptimizer(learning_rate=learning_rate)
    train = optimizer.minimize(cost, name='train')

    # Prediction
    correct_prediction = tf.equal(tf.argmax(tf_y, 1), tf.argmax(out_layer, 1))
    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32), name='accuracy')


```

- 현재 data를 numpy로 저장했기 때문에, 
- numpy 자료에 대해서 next_batch를 구현했습니다.


```python
import numpy as np

def next_batch(num, data, labels):
    '''
    Return a total of `num` random samples and labels. 
    '''
    idx = np.arange(0 , len(data))
    np.random.shuffle(idx)
    idx = idx[:num]
    data_shuffle = [data[ i] for i in idx]
    labels_shuffle = [labels[ i] for i in idx]

    return np.asarray(data_shuffle), np.asarray(labels_shuffle)
```

- label 자료들에 대해서, one hot encoding을 구현했습니다. 


```python
train_labels_encoded=np.zeros((len(train_labels),10))
for i in range(len(train_labels)):
    train_labels_encoded[i][train_labels[i]]=1
```


```python
test_labels_encoded=np.zeros((len(test_labels),10))
for i in range(len(test_labels)):
    test_labels_encoded[i][test_labels[i]]=1
```


```python

##########################
### TRAINING & EVALUATION
##########################
    
with tf.Session(graph=g) as sess:
    sess.run(tf.global_variables_initializer())

    for epoch in range(training_epochs):
        avg_cost = 0.
        total_batch = len(train_images_flatten) // batch_size

        for i in range(total_batch):
            batch_x, batch_y = next_batch(batch_size,train_images_flatten,train_labels_encoded)
            
            _, c = sess.run(['train', 'cost:0'], feed_dict={'features:0': batch_x,
                                                            'targets:0': batch_y})
            avg_cost += c
        
        train_acc = sess.run('accuracy:0', feed_dict={'features:0': train_images_flatten,
                                                      'targets:0': train_labels_encoded})
        
        print("Epoch: %03d | AvgCost: %.3f" % (epoch + 1, avg_cost / (i + 1)), end="\n")
       
    test_acc = sess.run('accuracy:0', feed_dict={'features:0': test_images_flatten,
                                                 'targets:0': test_labels_encoded})
    print('Test ACC: %.3f' % test_acc)
```


```python
with tf.Session(graph=g) as sess:
    test_acc=[]
    sess.run(tf.global_variables_initializer())
    for batch_size in np.arange(50,860,200):
        for epoch in range(training_epochs):
            avg_cost = 0.
            total_batch = len(train_images_flatten) // batch_size

            for i in range(total_batch):
                batch_x, batch_y = next_batch(batch_size,train_images_flatten,train_labels_encoded)

                _, c = sess.run(['train', 'cost:0'], feed_dict={'features:0': batch_x,
                                                                'targets:0': batch_y})
                avg_cost += c

            train_acc = sess.run('accuracy:0', feed_dict={'features:0': train_images_flatten,
                                                          'targets:0': train_labels_encoded})

        test_acc.append(sess.run('accuracy:0', feed_dict={'features:0': test_images_flatten,
                                                     'targets:0': test_labels_encoded}))
```


```python
import matplotlib.pyplot as plt
plt.scatter(np.arange(50, 850, 50), test_acc)
```
